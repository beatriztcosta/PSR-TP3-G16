#!/usr/bin/env python3

import rospy
import tf2_ros
from geometry_msgs.msg import Twist, PoseStamped
from sensor_msgs.msg import LaserScan, Image, CameraInfo
from nav_msgs.msg import Odometry
from gazebo_msgs.msg import ModelState, ModelStates, ContactsState
from gazebo_msgs.srv import DeleteModel, DeleteModelRequest

import math
import random
import subprocess
from colorama import Fore, Back, Style

import rospy
import tf_conversions  # Because of transformations
import tf2_ros
from prettytable import PrettyTable
from rospy import ServiceProxy
from cv_bridge import CvBridge
import sys
import cv2
import numpy as np


# ------------------------
#   DATA STRUCTURES
# ------------------------
from gazebo_msgs.srv import SetModelState


from driver import Driver, Normalizer

COLORS = ['red', 'green', 'blue']
PLAYERS = [[color+str(j) for j in range(1,4)] for color in COLORS] 
RGB = [(255,0,0), (0,255,0), (0,0,255)]


WAFFLE_MAX_LIN_VEL = 5.26
WAFFLE_MAX_ANG_VEL = 1.82

WAFFLE_WHEEL_DIST = 0.287


config = {
    "NUM_SENSORS": 11,
    "RESOLUTION": 7,
    "RANGE_MIN": -120*math.pi/180,
    "RANGE_MAX": 120*math.pi/180,
}


# binaries
CAMERA_B, INPUTS_B, LASER_B = 0b001, 0b010, 0b100 
READY = 0b111

## learning parameters
# ARS hyperparameters
DIRECTIONS = 4
BEST_DIRECTIONS = 16
NOISE_MIN = 0.03
NOISE_MAX = 0.04
LEARNING_RATE = 0.3
# sizes


def delete_model(unique_name):
   
    srv = ServiceProxy('/gazebo/delete_model', DeleteModel)

    req = DeleteModelRequest()

    req.model_name = unique_name

    resp = srv(req)

    if resp.success:
        print(resp.status_message, '(%s)' % unique_name)
        return 0
    else:
        print("failed to delete model [%s]: %s" %
              (unique_name, resp.status_message), file=sys.stderr)
        return 1 


def deleteAllModels():
    for color in 'red', 'green', 'blue':
        for p in rospy.get_param(f"/{color}_players"):
            delete_model(p)


def bash(cmd, blocking=True, verbose=False):
    if verbose:
        print("Executing command: " + cmd)
    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    if blocking:
        for line in p.stdout.readlines():
            print(line)
            p.wait()


def twistToDiff(speed, angular):
    sl = (2*speed - angular*WAFFLE_WHEEL_DIST)/2
    sr = angular*WAFFLE_WHEEL_DIST + sl
    return [sr, sl]

def diffToTwist(sr, sl):
    return [(sr+sl)/2, (sr-sl)/WAFFLE_WHEEL_DIST]



bridge = CvBridge()

class MultiBrain():
    def __init__(self, input_params):
        self.input_params = input_params
        self.learners = []
        self.n = 0
        self.pointer = 0
        input_size = input_params["RESOLUTION"] + input_params["NUM_SENSORS"] + 2 + 2
        self.weight_size = (1, input_size+1)
        self.currentWeights = np.zeros(self.weight_size)
        #self.currentWeights = np.array([[0.20061477035763844, 0.14324957959222312, 0.08152130281630943, 0.010761835907539187, -0.07438897441919387, -0.11763353425630188, -0.19910974231305306, -0.01852985871130197, 0.0031106606227670037, 0.007326302152042701, 0.01448675556642779, 0.009614205473124842, 0.024778952208224295, -0.022149656796659326, 0.002687257345506941, -0.018275314376151017, 0.002858643072713834, 0.00726029609060885, 0.0008829157167317709, 0.052903745736976246, -0.16822792904581405, -0.006246236178042087, 0.3116772461598515]])
        self.currentWeights = np.array([[0.2039244, 0.14529148,0.06503365,0.01212244,-0.06979054,-0.13069589
            ,-0.19038191,-0.01546823,0.00651391,0.00478352,0.01165758,-0.00090158
            , 0.01215455,-0.01241391,-0.0009678,-0.00395642,0.00866256,-0.01193278
            , 0.00490993,0.05815916,-0.17542923,-0.00469125,0.31233682
        ]])
        #self.currentWeights = np.array([[0.21431054160078758, 0.16167016546095872, 0.07045850832304099, 0.2216216024295199, -0.04101398275982003, -0.14661356993134747, -0.19469888892158788, -0.05280327129006949, 0.029113533602275685, 0.08365593820625683, 0.028318066009373005, -0.020178627757014754, -0.09543855134520472, -0.18230661666626066, -0.10320936072496668, -0.07974540611498637, 0.032630653640017854, 0.030378132808802194, -0.061106268574196855, 0.06754621438402827, -0.18978097900455224, -0.03385914291000995, 0.3080008059517819]])
    def addLearner(self, learner):
        self.learners.append( learner )
        self.n += 1
        self.rewards = np.zeros((DIRECTIONS*2*self.n,))
        self.weightNoise = np.zeros((DIRECTIONS*2*self.n,)+self.weight_size)

    def update(self, rewards, weightNoise):
        self.rewards[self.pointer*DIRECTIONS*2:(self.pointer+1)*DIRECTIONS*2] = rewards[:]
        self.weightNoise[self.pointer*DIRECTIONS*2:(self.pointer+1)*DIRECTIONS*2,:,:] = weightNoise[:,:,:]
        self.pointer += 1

        if self.pointer==self.n:
            self.distributeLearning()
            self.pointer = 0
            
    def distributeLearning(self):
        step = np.zeros(self.currentWeights.shape)
        best_idxs = [i[1] for i in sorted([(max(self.rewards[idx*2],self.rewards[idx*2+1] ), idx) for idx in range(DIRECTIONS*self.n)],reverse=True)]
        G = 1
        sigma = 0
        for idx in best_idxs:
            print( self.rewards[idx*2], self.rewards[idx*2+1] )
            if max(self.rewards[idx*2], self.rewards[idx*2+1])<0:
                break

            diff = abs(self.rewards[idx*2] - self.rewards[idx*2+1])
            sigma += diff*G
            step += self.weightNoise[idx*2,:,:]*(self.rewards[idx*2] - self.rewards[idx*2+1])*G
            G *= 0.95

        self.currentWeights += LEARNING_RATE / max(sigma, 0.01) * step
        print(list(self.currentWeights[0,:]))
        for learner in self.learners:
            learner.currentWeights[:,:] = self.currentWeights[:,:]
            learner.generateNoise()

        

def shuffle_along_axis(a, axis):
    idx = np.random.rand(*a.shape).argsort(axis=axis)
    return np.take_along_axis(a,idx,axis=axis)


class Learner(Driver):
    def __init__(self, name, team, weights, normalizer, input_params, brain=None):
        input_size = input_params["RESOLUTION"] + input_params["NUM_SENSORS"] + 2 + 2
        self.weight_size = (1, input_size+1)
        if weights:
            self.currentWeights = weights
        else:
            self.currentWeights = np.zeros(self.weight_size)

        if brain:
            brain.addLearner(self)
            self.currentWeights[:,:] = brain.currentWeights[:,:]

        self.name = name
        self.brain = brain
        self.rewards = np.zeros((DIRECTIONS*2,))
        self.weightNoise = np.zeros((DIRECTIONS*2,)+self.weight_size)
        self.currentIdx = 0
        self.generateNoise()
        self.weights = self.currentWeights + self.weightNoise[0, :, :]
        super().__init__(name, team, normalizer, input_params)


    def endEpisode(self, reward):
        self.rewards[self.currentIdx] = reward

        self.currentIdx += 1
        if self.currentIdx >= DIRECTIONS*2:
            self.currentIdx = 0
            self.update()
        else:
            self.weights = self.currentWeights + self.weightNoise[self.currentIdx, :, :]


    def update(self):
        if self.brain:
            self.brain.update(self.rewards, self.weightNoise)
            return

        step = np.zeros(self.currentWeights.shape)
        best_idxs = [i[1] for i in sorted([(max(self.rewards[idx*2],self.rewards[idx*2+1] ), idx) for idx in range(DIRECTIONS)],reverse=True)]
        G = 1
        sigma = 0
        print("rewards:", self.name)
        for idx in best_idxs:
            print( self.rewards[idx*2], self.rewards[idx*2+1] )
            if max(self.rewards[idx*2] - self.rewards[idx*2+1])<0:
                break
            diff = abs(self.rewards[idx*2] - self.rewards[idx*2+1])
            sigma += diff*G
            step += self.weightNoise[idx*2,:,:]*(self.rewards[idx*2] - self.rewards[idx*2+1])*G
            G*=0.95

        self.currentWeights += LEARNING_RATE / max(sigma, 0.01) * step
        print(f"AFTER {self.name}: ", self.currentWeights)

        self.generateNoise()
        
    def generateNoise(self):
        self.currentIdx = 0
        noise = np.random.randn(DIRECTIONS, *self.weightNoise.shape[1:])

        noiseAmplify = np.zeros((DIRECTIONS,)) if rospy.get_param('/disable_learning') else np.linspace(NOISE_MIN, NOISE_MAX, DIRECTIONS)
        np.random.shuffle(noiseAmplify)

        for d in range(DIRECTIONS):
            self.weightNoise[d*2,:,:] = noise[d,:,:]*noiseAmplify[d]
            self.weightNoise[d*2+1,:,:] = -noise[d,:,:]*noiseAmplify[d]

      
        self.weights = self.currentWeights + self.weightNoise[self.currentIdx, :, :]
  
    def act(self):

        if self.ready != READY:
            return
        
        RESOLUTION = self.input_params["RESOLUTION"]
        NUM_SENSORS = self.input_params["NUM_SENSORS"]

        self.normalizer.observe(self.inputs)
        I = self.inputs
        symetric_inputs = np.concatenate( [I[:RESOLUTION][::-1], I[RESOLUTION:RESOLUTION+NUM_SENSORS][::-1], I[-4:-2][::-1], I[-2:-1], -I[-1:] ] )  
        
        compound_inputs_r = np.concatenate([self.normalizer.normalize(self.inputs), np.ones((1,))])
        compound_inputs_l = np.concatenate([self.normalizer.normalize(symetric_inputs), np.ones((1,))])

        self.ready = 0b0 #reset ready state

        actionr = np.tanh( self.weights.dot(compound_inputs_r) ) * WAFFLE_MAX_LIN_VEL #values between -1 and 1
        actionl = np.tanh( self.weights.dot(compound_inputs_l) ) * WAFFLE_MAX_LIN_VEL 
        
        if self.sensors[NUM_SENSORS//2]>5 and self.inputs[RESOLUTION//2-1:RESOLUTION//2+2].sum()<=0.0:
            sp_linear, sp_angular = diffToTwist( -1, -1.5 )
        else:
            sp_linear, sp_angular = diffToTwist( (actionr[0] + self.speed[0])/2, (actionl[0] + self.speed[1])/2 )
        twist = Twist()
        twist.linear.x = sp_linear
        twist.angular.z = sp_angular 
        self.publisher_command.publish(twist)




class Teacher:

    def __init__(self, learners):

        # Verify that all the required parameters exist
        self.game_over = True
        self.learners = learners
        self.locations = [(x+0.5,y+0.5) for x in range(1,8) for y in range(-3,3)]
        self.locationidx = 0
        try:
            existing_params = rospy.get_param_names()
        except rospy.ROSException:
            print("Could not get param name")

        required_params = ['/killed_duration', '/game_duration', '/positive_score', '/negative_score', '/best_hunter_score',
                           '/best_survivor_score', '/red_players', '/green_players', '/blue_players']
        
        for required_param in required_params:
            if not required_param in existing_params:
                raise ValueError('Required ros parameter ' + required_param +
                                 ' does not exist. Are you sure you load the game params.yaml?')

        self.params = {'killed_duration': rospy.get_param('/killed_duration'),
                       'game_duration': rospy.get_param('/game_duration'),
                       'positive_score': rospy.get_param('/positive_score'),
                       'immunity_duration': rospy.get_param('/immunity_duration'),
                       'negative_score': rospy.get_param('/negative_score'),
                       'best_hunter_score': rospy.get_param('/best_hunter_score'),
                       'best_survivor_score': rospy.get_param('/best_survivor_score'),
                       'disable_learning': rospy.get_param('/disable_learning'),
                       'red': rospy.get_param('/red_players'),
                       'green': rospy.get_param('/green_players'),
                       'blue': rospy.get_param('/blue_players')}

        # Create a dictionary so we can retrieve the players of a team using the team color
        self.score = {'red': 0, 'green': 0, 'blue': 0}
        self.final_score = {'red': 0, 'green': 0, 'blue': 0}

        rospy.wait_for_service('/gazebo/set_model_state')  # check that this service exists

       
        rospy.sleep(0.1)

        # Create an instance for each player
        self.players = {}
        count = 1
        for player in self.params['red']:
            self.players[player] = PlayerInfo(player, self.params, my_team='red', prey_team='green', hunter_team='blue',
                                              callbackHuntedEvent=self.callbackHuntedEvent, killPlayer=self.killPlayer, number=count)
            count += 1
        for player in self.params['green']:
            self.players[player] = PlayerInfo(player, self.params, my_team='green', prey_team='blue', hunter_team='red',
                                              callbackHuntedEvent=self.callbackHuntedEvent, killPlayer=self.killPlayer, number=count)
            count += 1
        for player in self.params['blue']:
            self.players[player] = PlayerInfo(player, self.params, my_team='blue', prey_team='red', hunter_team='green',
                                              callbackHuntedEvent=self.callbackHuntedEvent, killPlayer=self.killPlayer, number=count)
            count += 1

        self.game_start_tic = rospy.Time.now()
        self.timer_check_game = rospy.Timer(rospy.Duration(0.1), self.callbackCheckGame, oneshot=False)
        self.timer_end_game = rospy.Timer(rospy.Duration(self.params['game_duration']), self.callbackEndGame,
                                          oneshot=False)

        for color in 'red', 'green', 'blue':
            for p in rospy.get_param(f"/{color}_players"):
                self.movePlayerToArena(p)

        
        self.game_over = False

    def callbackEndGame(self, event):

        self.game_over = True

        # Print scoreboard
        self.printScores()

        # Game over message
        if self.final_score['red'] == self.final_score['green'] and self.final_score['red'] == self.final_score['blue']:
            print(Style.BRIGHT + 'Game Over! It is a tie!!!')
        elif self.final_score['red'] > max(self.final_score['green'], self.final_score['blue']):
            print(Style.BRIGHT + 'Game Over! Team ' + Fore.RED + 'Red' + Fore.RESET + ' wins!!!')
        elif self.final_score['green'] > max(self.final_score['red'], self.final_score['blue']):
            print(Style.BRIGHT + 'Game Over! Team ' + Fore.GREEN + 'Green' + Fore.RESET + ' wins!!!')
        elif self.final_score['blue'] > max(self.final_score['green'], self.final_score['red']):
            print(Style.BRIGHT + 'Game Over! Team ' + Fore.BLUE + 'Blue' + Fore.RESET + ' wins!!!')
        

        for learner in self.learners:
            learner.endEpisode( self.players[learner.name].score )
            #self.movePlayerToArena(learner.name)
        rospy.sleep(0.2)
        for learner in self.learners:
            self.players[learner.name].reset()
        
        self.score = {'red': 0, 'green': 0, 'blue': 0}
        self.final_score = {'red': 0, 'green': 0, 'blue': 0}

        self.game_over = False
        
        
        #rospy.signal_shutdown('Game finished')

    def printScores(self):
        best_hunter, best_survivor = self.getBestHunterAndSurvivor()

        print(Style.BRIGHT + '\nPlayer by player scores:' + Style.RESET_ALL)
        table = PrettyTable(
            [Back.LIGHTWHITE_EX + "Player", "Team", "#Hunted", "#Preyed", "Killed", "Spawn" + Style.RESET_ALL])

        for player in self.players.values():
            num_hunted, num_preyed = str(player.num_hunted), str(player.num_preyed)
            if player.name == best_hunter:
                num_hunted = Back.LIGHTCYAN_EX + str(player.num_hunted) + Style.RESET_ALL
            elif player.name == best_survivor:
                num_preyed = Back.MAGENTA + str(player.num_preyed) + Style.RESET_ALL

            time_to_spawn = self.params['killed_duration'] - (rospy.Time.now() - player.stamp_killed).to_sec()

            if time_to_spawn < 0:
                time_to_spawn = '---'
            else:
                time_to_spawn = "{:.1f}".format(time_to_spawn)
            table.add_row([player.colorama_color + player.name + Fore.RESET,
                           player.colorama_color + player.my_team + Fore.RESET,
                           num_hunted, num_preyed, player.killed, time_to_spawn])

        table.align = 'c'
        table.align[Back.LIGHTWHITE_EX + "Player"] = 'l'
        table.align['Team'] = 'l'
        print(table)

        print('Best hunter: ' + Fore.LIGHTCYAN_EX + str(best_hunter) + Style.RESET_ALL +
              ' Best survivor: ' + Fore.MAGENTA + str(best_survivor) + Style.RESET_ALL)

        self.score = {team: sum(self.players[p].score for p in self.params[team]) for team in ['red','green','blue']}
        print(Style.BRIGHT + '\nTeam scores:' + Style.RESET_ALL)
        table = PrettyTable([Back.LIGHTWHITE_EX + "Team", "Raw Score", "Final Score" + Style.RESET_ALL])
        for team_key, score in self.score.items():
            self.final_score[team_key] = score
            if best_hunter in self.params[team_key]:
                self.final_score[team_key] += self.params['best_hunter_score']
            if best_survivor in self.params[team_key]:
                self.final_score[team_key] += self.params['best_survivor_score']
            table.add_row([getattr(Fore, team_key.upper()) + team_key + Style.RESET_ALL, str(score),
                           str(self.final_score[team_key])])

        print(table)
        game_time = "{:.1f}".format((rospy.Time.now() - self.game_start_tic).to_sec())
        print('Game time: ' + game_time + ' out of ' + str(self.params['game_duration']))

    def getBestHunterAndSurvivor(self):

        ps = [(player, self.players[player].num_hunted, self.players[player].num_preyed) for player in
              self.players.keys()]
        hunt_values = [self.players[player].num_hunted for player in self.players.keys()]
        prey_values = [self.players[player].num_preyed for player in self.players.keys()]

        best_hunter, maximum_num_hunts, _ = max(ps, key=lambda item: item[1])
        if hunt_values.count(maximum_num_hunts) > 1:
            best_hunter = None

        best_survivor, _, minimum_num_preyed = min(ps, key=lambda item: item[2])
        if prey_values.count(minimum_num_preyed) > 1:
            best_survivor = None

        return best_hunter, best_survivor

    def callbackCheckGame(self, event):
        if self.game_over:
            return

        # reward for speed
        now = rospy.Time.now()
        for learner in self.learners:
            player = self.players[learner.name]
            if not player.killed:
                pass
                ##player.score += max(0, abs(learner.speed.sum()) )/30.0
            elif (now - player.stamp_killed).to_sec() > self.params['killed_duration']:
                player.stamp_resuscitated = rospy.Time.now()
                self.movePlayerToArena(learner.name)
                rospy.logwarn("Resuscitating %s", learner.name)

    def callbackHuntedEvent(self, hunter, prey):
        if self.game_over:
            return

        if not self.players[prey].killed:
            rospy.logwarn(hunter + ' hunted ' + prey)
            self.killPlayer(prey)
            now = rospy.Time.now()
            if (now - self.players[prey].stamp_resuscitated).to_sec() <= self.params['immunity_duration']:
                rospy.logwarn(f"{prey} is immune")
                return
            if (now - self.players[hunter].stamp_resuscitated).to_sec() <= self.params['immunity_duration']:
                rospy.logwarn(f"{hunter} (hunter) is immune")
                return
            self.players[hunter].num_hunted += 1
            self.players[prey].num_preyed += 1
            self.players[hunter].score += self.params['positive_score']
            self.players[prey].score += self.params['negative_score']

    def killPlayer(self, name, modify_score=0):
        self.players[name].killed = True
        self.players[name].score += modify_score
        self.players[name].stamp_killed = rospy.Time.now()
        self.removePlayerFromArena(name)

    def removePlayerFromArena(self, name):
        # Arena limbo area has following dimensions:
        # x from -1.5 to 1.5
        # y from 3.5 to 7
        x = random.random() * 3 - 1.5
        y = random.random() * 3.5 + 3.5
        self.warpPlayer(name, x, y, 0)

    def movePlayerToArena(self, name):
        # Arena area has following dimensions:
        # x from -8 to 8
        # y from -2.5 to 2.5
        x,y = self.locations[self.locationidx]
        self.locationidx = (self.locationidx+1)%len(self.locations)
        self.players[name].killed = False
        self.warpPlayer(name, x, y, random.random() * math.pi * 2 - math.pi)

    def warpPlayer(self, name, x, y, yaw):
        state_msg = ModelState()
        state_msg.model_name = name
        state_msg.pose.position.x = x
        state_msg.pose.position.y = y
        quaternion = tf_conversions.tf.transformations.quaternion_from_euler(0, 0, yaw)
        state_msg.pose.orientation.x = quaternion[0]
        state_msg.pose.orientation.y = quaternion[1]
        state_msg.pose.orientation.z = quaternion[2]
        state_msg.pose.orientation.w = quaternion[3]

        try:
            set_state = rospy.ServiceProxy('/gazebo/set_model_state', SetModelState)
            resp = set_state(state_msg)
        except rospy.ServiceException as e:
            print("Service call failed:" + str(e))


class PlayerInfo:

    def __init__(self, name, players, my_team, prey_team, hunter_team, callbackHuntedEvent, killPlayer, number=1):
        self.name = name
        self.number = number
        self.players = players
        self.colorama_color = getattr(Fore, my_team.upper())
        self.my_team, self.prey_team, self.hunter_team = my_team, prey_team, hunter_team
       


        print('Teacher configuring ' + self.name + ', from team ' + self.my_team + ', hunting ' + str(
            self.players[self.prey_team]) + ' and fleeing from ' + str(self.players[self.hunter_team]))

        self.callbackHuntedEvent = callbackHuntedEvent
        self.killPlayer = killPlayer

        self.killed = False
        self.stamp_resuscitated = rospy.Time.now()
        self.stamp_killed = rospy.Time.now() - rospy.Duration.from_sec(10)        

        self.subscriber_contact = rospy.Subscriber('/' + self.name + '/contact', ContactsState,
                                                   self.callbackContactReceived)

        self.reset()
        print(self.__str__())  # print a report after initialization

    def reset(self):
        self.score = 0
        self.num_hunted = 0
        self.num_preyed = 0

    def callbackContactReceived(self, msg):
        now = rospy.Time.now()
        for state in msg.states:

            if state.collision2_name.split('::')[0] == self.name:
                state.collision1_name, state.collision2_name = state.collision2_name, state.collision1_name

            object1, collision_obj1, _ = state.collision1_name.split('::')
            object2, collision_obj2, _ = state.collision2_name.split('::')
            if object1 != self.name or self.killed: continue

            if object2 in self.players[self.prey_team]:
                self.callbackHuntedEvent(self.name, object2)
           
            elif collision_obj2.startswith("Wall") or object2 in self.players[self.my_team] and not self.params["disable_learning"]:
                if (now - self.stamp_resuscitated).to_sec() > 2 and collision_obj2.startswith("Wall"): #immunity diration
                    rospy.logwarn(self.name + ' bumped into a wall ')
                    self.killPlayer(self.name, -2)
                else:
                    rospy.logwarn(self.name + ' bumped into a wall while immune')
                    self.killPlayer(self.name, 0)

    def __str__(self):
        s = 'Player ' + self.colorama_color + self.name + Style.RESET_ALL + ' (team ' + self.my_team + ')\t'
        s += 'Hunted: ' + str(self.num_hunted) + ' ; Preyed: ' + str(self.num_preyed)
        return s


# ------------------------
# GLOBAL VARIABLES
# ------------------------

def main():
    rospy.init_node('p_learner', anonymous=True)  # initialize the ros node
    #deleteAllModels()
    #return
    normalizer = Normalizer(config["RESOLUTION"] + config["NUM_SENSORS"] + 2 + 2)
    rospy.sleep(0.5)  # make sure the rospy time works
    learners = []
    brain = MultiBrain(config) # {team: MultiBrain() for team in ['red', 'green', 'blue']}
    for color in 'red', 'green', 'blue':
        for p in rospy.get_param(f"/{color}_players"):
            myteamidx = max([idx for idx, n in enumerate(COLORS) if p.startswith(n)] or [0])
            learners.append( Learner(p, myteamidx, None, normalizer, config, brain) )
            #delete_model(p)
    teacher = Teacher(learners)

    rospy.spin()


if __name__ == '__main__':
    main()
